{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# optimization & training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 학습을 해보자\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_x, train_y),(test_x, test_y) = datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델에  input의 shape를 알려주고\n",
    "#클래스 개수를 알려줘야한다.\n",
    "input_shape = (28,28, 1)\n",
    "num_classes = 10\n",
    "inputs = layers.Input(shape=input_shape)\n",
    "#인풋을 이렇게 바로 줄 수 있다.\n",
    "#첫레이여만 inputs가 들어가는 것이다.\n",
    "#filter32 개\n",
    "net = layers.Conv2D(32,3,padding='SAME')(inputs)\n",
    "net = layers.Activation('relu')(net)\n",
    "net = layers.Conv2D(32,3,padding='SAME')(net)\n",
    "net = layers.Activation('relu')(net)\n",
    "net = layers.MaxPool2D((2,2))(net)\n",
    "net = layers.Dropout(0.25)(net)\n",
    "# net.shape TensorShape([None, 28, 28, 32])가 된다. max pooling으로 크기가 줄어든 것\n",
    "\n",
    "net = layers.Conv2D(64,3,padding='SAME')(net)\n",
    "net = layers.Activation('relu')(net)\n",
    "net = layers.Conv2D(64,3,padding='SAME')(net)\n",
    "net = layers.Activation('relu')(net)\n",
    "net = layers.MaxPool2D((2,2))(net)\n",
    "net = layers.Dropout(0.25)(net)\n",
    "\n",
    "#net.shape TensorShape([None, 7, 7, 64])\n",
    "#위가 feature extraction 아래가 fully connected\n",
    "net = layers.Flatten()(net)\n",
    "net = layers.Dense(512)(net)\n",
    "net = layers.Activation('relu')(net)\n",
    "net = layers.Dropout(0.5)(net)\n",
    "net = layers.Dense(10)(net)\n",
    "#마지막에 출력되는 output layer에는 클래스를 10개로 바꾸어줘야 한다.\n",
    "#그래서 클래스 개수만큼 노드를 만들어줘야 하고, 이 부분의 확률 값이 답이다.\n",
    "net = layers.Activation('softmax')(net)\n",
    "model = tf.keras.Model(inputs=inputs, outputs=net, name='BASIC_CNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"BASIC_CNN\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               1606144   \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,676,266\n",
      "Trainable params: 1,676,266\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습 과정  \n",
    "## Data -> model -> logit > result\n",
    "##    model <-  optm <-  loss < logit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델에서 예측을 하고, loss를 계산하고, optm를 해보자\n",
    "## Optimization\n",
    "    - 모델 학습하기 전 설정\n",
    " - Loss Function\n",
    " - Optimization\n",
    " - Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss function 방법 확인\n",
    "# categorical vs binary\n",
    "# 클래스가 두 개 인 경우(cat vs dog)는 binary_cross_entropy 를 사용한다.\n",
    "# 클래스가 여러개 인 경우는 categorical_crossentropy를 사용한다\n",
    "loss = 'binary_crossentropy'\n",
    "loss = 'categorical_crossentropy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function tensorflow.python.keras.losses.categorical_crossentropy(y_true, y_pred, from_logits=False, label_smoothing=0)>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#만약 one-hot-encoding을 안했다면\n",
    "#spqrse_categorical_crossentropy를 사용한다.\n",
    "tf.keras.losses.sparse_categorical_crossentropy\n",
    "\n",
    "#원핫 인코딩을 했다면\n",
    "tf.keras.losses.categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function tensorflow.python.keras.losses.binary_crossentropy(y_true, y_pred, from_logits=False, label_smoothing=0)>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#onehot encoding을 한 binary 클래스라면\n",
    "tf.keras.losses.binary_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function tensorflow.python.keras.losses.sparse_categorical_crossentropy(y_true, y_pred, from_logits=False, axis=-1)>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#우리는 one-hot-encoding을 하지 않을 때로 하자\n",
    "loss_func = tf.losses.sparse_categorical_crossentropy\n",
    "loss_func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics\n",
    "## 모델을 평가하는 방법\n",
    "### accuracy를 이름으로 넣는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy는 전체 문제에서 몇 개를 맟추었냐\n",
    "#두 방법이 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.metrics.Accuracy at 0x1c68b0daa08>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.metrics.Accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.metrics.Precision at 0x1c68b0dd408>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.metrics.Precision()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.metrics.Accuracy at 0x1c68b0da1c8>]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#우리는 tf.keras.metrics.Accuracy() 이걸 사용하자\n",
    "#리스트 안에 넣어줘야 한다.\n",
    "#그 이유는 평가를 할 때, list안에 recall, precision 등을 넣어줄 수 있기 때문이다.\n",
    "# metrics = [tf.keras.metrics.Accuracy(), 'recall', 'precision'] 이렇게 말이다.\n",
    "metrics = [tf.keras.metrics.Accuracy()]\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#우리는 loss function을 정해주었고, 이에 따른 accuracy를 얻도록 하였다\n",
    "#optimization을 하도록 하자"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compile\n",
    "## optimizer 적용\n",
    "- 'sgd'\n",
    "- 'msprop'\n",
    "- 'adam'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.optimizer_v2.adam.Adam at 0x1c68a7cafc8>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optm = tf.keras.optimizers.Adam()\n",
    "optm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss는 sparse_categorical_crossenctropy이고\n",
    "#optm은  adam을 사용\n",
    "#이제 model에 compile을 해줘야 한다.\n",
    "model.compile(optimizer=optm, loss = loss_func, metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Dataset\n",
    "학습에 사용할 데이터 셋을 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x.shape , train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#차원이 4차원으로 들어가야하는데, 3차원이다.\n",
    "#즉, channel이 없다. 그래서 차원을 늘려줘야 한다.\n",
    "test_x.shape , test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#기존에 늘리던 방법\n",
    "tf.expand_dims(train_x, - 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#차원 수 늘리기 텐서플로 공식 홈페이지에서 추천해주는 방법\n",
    "train_x[:,:,:,tf.newaxis].shape\n",
    "##차원 수 늘리기 텐서플로 공식 홈페이지에서 추천해주는 방법2 spread 사용\n",
    "train_x = train_x[... , tf.newaxis]\n",
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = test_x[..., tf.newaxis]\n",
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rescaling\n",
    "import numpy as np\n",
    "np.min(train_x) , np.max(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0과 1사이의 값으로 rescaling을 해주자\n",
    "train_x.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_x / 255.\n",
    "test_x = test_x/ 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.min(train_x) , np.max(train_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "본격적으로 학습 들어가기\n",
    "학습용 하이퍼파라미터 설정\n",
    "- num_epochs\n",
    "- batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#epoch은 batch 사이즈에 맞게 한 번 모델 적용을 시킨 것\n",
    "#책을 한 번 다 봤다면 1 에폭, 2번 봤다면 2 에폭\n",
    "#실제로 할 때는 에폭 수를 늘려줘야 한다.\n",
    "num_epochs = 1\n",
    "batch_size = 32\n",
    "#책이 6만 장인데, 32장 씩 읽어가는 것이다.\n",
    "type(num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#실제로 우리가 한 것은\n",
    "# 1, 모델을 설계(모델에 layer을 담아줌)\n",
    "# 2, optm 을 설정해주었다. compile\n",
    "# 3, model.fit을 해주어야 \n",
    "# evaluation할 때는 shuffle을 안해도 된다\n",
    "# shuffle을 하는 이유는 bias에 걸린다. overfitting에 걸린다는 것이다.\n",
    "# 인간이 책을 보고 공부하는데, 6 챕터를 하나씩하나씩 보다보면, 이전에 공부했던 것들은 까먹게 된다.\n",
    "# bias에 걸리게 되는 것이다.\n",
    "model.fit(train_x, train_y,\n",
    "         batch_size=batch_size,\n",
    "         shuffle=True,\n",
    "         epochs = num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check History\n",
    "학습 과정(History) 결과 확인"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
